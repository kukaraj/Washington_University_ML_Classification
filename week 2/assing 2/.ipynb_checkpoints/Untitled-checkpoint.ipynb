{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 321,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import string\n",
    "import re\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.dummy import DummyClassifier\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 322,
   "metadata": {},
   "outputs": [],
   "source": [
    "products = pd.read_csv('amazon_baby_subset.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 323,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 53072 entries, 0 to 53071\n",
      "Data columns (total 4 columns):\n",
      "name         52982 non-null object\n",
      "review       52831 non-null object\n",
      "rating       53072 non-null int64\n",
      "sentiment    53072 non-null int64\n",
      "dtypes: int64(2), object(2)\n",
      "memory usage: 1.6+ MB\n"
     ]
    }
   ],
   "source": [
    "products.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 324,
   "metadata": {},
   "outputs": [],
   "source": [
    "important_words = pd.read_json('important_words.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 325,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 193 entries, 0 to 192\n",
      "Data columns (total 1 columns):\n",
      "0    193 non-null object\n",
      "dtypes: object(1)\n",
      "memory usage: 1.6+ KB\n"
     ]
    }
   ],
   "source": [
    "important_words.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 326,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    Stop Pacifier Sucking without tears with Thumb...\n",
       "1      Nature's Lullabies Second Year Sticker Calendar\n",
       "2      Nature's Lullabies Second Year Sticker Calendar\n",
       "3                          Lamaze Peekaboo, I Love You\n",
       "4    SoftPlay Peek-A-Boo Where's Elmo A Children's ...\n",
       "5                            Our Baby Girl Memory Book\n",
       "6    Hunnt&reg; Falling Flowers and Birds Kids Nurs...\n",
       "7    Blessed By Pope Benedict XVI Divine Mercy Full...\n",
       "8    Cloth Diaper Pins Stainless Steel Traditional ...\n",
       "9    Cloth Diaper Pins Stainless Steel Traditional ...\n",
       "Name: name, dtype: object"
      ]
     },
     "execution_count": 326,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "products.name[0:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 327,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "26438"
      ]
     },
     "execution_count": 327,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "products.review[products.sentiment==1].count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 328,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "26393"
      ]
     },
     "execution_count": 328,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "products.review[products.sentiment==-1].count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 329,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "241"
      ]
     },
     "execution_count": 329,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "products.review.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 330,
   "metadata": {},
   "outputs": [],
   "source": [
    "products['review'] = products.review.fillna('')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 331,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 331,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "products.review.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 332,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_punctuation(text):\n",
    "    return re.sub(r'[^\\w\\s]','',text) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 333,
   "metadata": {},
   "outputs": [],
   "source": [
    "products['review_clean'] = products.review.apply(lambda x: remove_punctuation(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 334,
   "metadata": {},
   "outputs": [],
   "source": [
    "important_words = important_words[0].tolist()\n",
    "for word in important_words:\n",
    "    products[word] = products['review_clean'].apply(lambda s : s.split().count(word))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 335,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 53072 entries, 0 to 53071\n",
      "Columns: 198 entries, name to either\n",
      "dtypes: int64(195), object(3)\n",
      "memory usage: 80.2+ MB\n"
     ]
    }
   ],
   "source": [
    "products.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 336,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>review</th>\n",
       "      <th>rating</th>\n",
       "      <th>sentiment</th>\n",
       "      <th>review_clean</th>\n",
       "      <th>baby</th>\n",
       "      <th>one</th>\n",
       "      <th>great</th>\n",
       "      <th>love</th>\n",
       "      <th>use</th>\n",
       "      <th>...</th>\n",
       "      <th>seems</th>\n",
       "      <th>picture</th>\n",
       "      <th>completely</th>\n",
       "      <th>wish</th>\n",
       "      <th>buying</th>\n",
       "      <th>babies</th>\n",
       "      <th>won</th>\n",
       "      <th>tub</th>\n",
       "      <th>almost</th>\n",
       "      <th>either</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>11291</th>\n",
       "      <td>First Years Premiere True Fit Signature Series...</td>\n",
       "      <td>I am so happy with my purchase of this car sea...</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>I am so happy with my purchase of this car sea...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7869</th>\n",
       "      <td>Aden and Anais UpAwaySwddleBlnkts</td>\n",
       "      <td>As a mom of a 2mo old, I want to encourage oth...</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>As a mom of a 2mo old I want to encourage othe...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17966</th>\n",
       "      <td>Baby Chef Ultimate Baby Food Maker</td>\n",
       "      <td>I absolutely love this baby food maker. This w...</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>I absolutely love this baby food maker This wa...</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10520</th>\n",
       "      <td>Regalo Easy Open 50 Inch Super Wide Walk Thru ...</td>\n",
       "      <td>Gate works great. The only problem I have is t...</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>Gate works great The only problem I have is th...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50555</th>\n",
       "      <td>Sassy Terry Teethers 2Pk</td>\n",
       "      <td>It's just like any piece of cloth. Not worth t...</td>\n",
       "      <td>2</td>\n",
       "      <td>-1</td>\n",
       "      <td>Its just like any piece of cloth Not worth the...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 198 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                    name  \\\n",
       "11291  First Years Premiere True Fit Signature Series...   \n",
       "7869                   Aden and Anais UpAwaySwddleBlnkts   \n",
       "17966                 Baby Chef Ultimate Baby Food Maker   \n",
       "10520  Regalo Easy Open 50 Inch Super Wide Walk Thru ...   \n",
       "50555                           Sassy Terry Teethers 2Pk   \n",
       "\n",
       "                                                  review  rating  sentiment  \\\n",
       "11291  I am so happy with my purchase of this car sea...       5          1   \n",
       "7869   As a mom of a 2mo old, I want to encourage oth...       5          1   \n",
       "17966  I absolutely love this baby food maker. This w...       5          1   \n",
       "10520  Gate works great. The only problem I have is t...       4          1   \n",
       "50555  It's just like any piece of cloth. Not worth t...       2         -1   \n",
       "\n",
       "                                            review_clean  baby  one  great  \\\n",
       "11291  I am so happy with my purchase of this car sea...     0    1      0   \n",
       "7869   As a mom of a 2mo old I want to encourage othe...     0    0      0   \n",
       "17966  I absolutely love this baby food maker This wa...     2    0      1   \n",
       "10520  Gate works great The only problem I have is th...     0    1      1   \n",
       "50555  Its just like any piece of cloth Not worth the...     1    0      0   \n",
       "\n",
       "       love  use  ...  seems  picture  completely  wish  buying  babies  won  \\\n",
       "11291     0    0  ...      0        0           0     0       0       0    0   \n",
       "7869      1    1  ...      0        0           0     0       0       0    0   \n",
       "17966     3    0  ...      0        0           0     0       0       0    0   \n",
       "10520     0    0  ...      0        0           0     0       0       0    0   \n",
       "50555     0    0  ...      0        0           0     0       0       0    0   \n",
       "\n",
       "       tub  almost  either  \n",
       "11291    0       0       0  \n",
       "7869     0       0       0  \n",
       "17966    0       0       0  \n",
       "10520    0       0       0  \n",
       "50555    0       0       0  \n",
       "\n",
       "[5 rows x 198 columns]"
      ]
     },
     "execution_count": 336,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "products.sample(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 337,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data, validation_data = train_test_split(products, test_size=0.2, random_state=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 338,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_numpy_data(dataframe, features, label):\n",
    "    dataframe['constant'] = 1\n",
    "    features = ['constant'] + features\n",
    "    feature_frame = dataframe[features]\n",
    "    feature_matrix = feature_frame.to_numpy()\n",
    "    label_sarray = dataframe[label]\n",
    "    label_array = label_sarray.to_numpy()\n",
    "    return (feature_matrix, label_array)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 339,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  \n"
     ]
    }
   ],
   "source": [
    "feature_matrix_train, sentiment_train = get_numpy_data(train_data, important_words, 'sentiment')\n",
    "feature_matrix_valid, sentiment_valid = get_numpy_data(validation_data, important_words, 'sentiment') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 340,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_probability(feature_matrix, coefficients):\n",
    "    import math\n",
    "    score = np.dot(feature_matrix, coefficients)\n",
    "    predictions = 1. /(1 + np.exp(-score))\n",
    "    \n",
    "    return predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 341,
   "metadata": {},
   "outputs": [],
   "source": [
    "def feature_derivative_with_L2(errors,feature,coefficient,l2_penalty,feature_is_constant):\n",
    "    derivative = np.dot(errors, feature)\n",
    "    \n",
    "    if not feature_is_constant:\n",
    "        derivative -= l2_penalty\n",
    "    \n",
    "    return derivative"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 342,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_log_likelihood_with_L2(feature_matrix, sentiment, coefficients, l2_penalty):\n",
    "    indicator = (sentiment==+1)\n",
    "    scores = np.dot(feature_matrix, coefficients)\n",
    "    \n",
    "    lp = np.sum((indicator-1)*scores - np.log(1. + np.exp(-scores))) - l2_penalty*np.sum(coefficients[1:]**2)\n",
    "    \n",
    "    return lp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 343,
   "metadata": {},
   "outputs": [],
   "source": [
    "def logistic_regression_with_L2(feature_matrix,sentiment,initial_coefficients,step_size,l2_penalty,max_iter):\n",
    "    coefficients = np.array(initial_coefficients)\n",
    "    \n",
    "    for itr in range(max_iter):\n",
    "        predictions = predict_probability(feature_matrix, coefficients)\n",
    "        indicator = (sentiment==+1)\n",
    "        errors = indicator-predictions\n",
    "        \n",
    "        for j in range(len(coefficients)):\n",
    "            is_intercept = (j == 0)\n",
    "            derivative = feature_derivative_with_L2(errors,feature_matrix[:,j],coefficients,l2_penalty,is_intercept)\n",
    "            coefficients[j] += (step_size*derivative)\n",
    "            \n",
    "        if itr <= 15 or (itr <= 100 and itr % 10 == 0) or (itr <= 1000 and itr % 100 == 0) \\\n",
    "        or (itr <= 10000 and itr % 1000 == 0) or itr % 10000 == 0:\n",
    "            lp = compute_log_likelihood_with_L2(feature_matrix, sentiment, coefficients, l2_penalty)\n",
    "            print ('iteration %*d: log likelihood of observed labels = %.8f' % \\\n",
    "                (int(np.ceil(np.log10(max_iter))), itr, lp))\n",
    "    return coefficients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 344,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iteration   0: log likelihood of observed labels = -29244.82592989\n",
      "iteration   1: log likelihood of observed labels = -29068.30159358\n",
      "iteration   2: log likelihood of observed labels = -28898.56599089\n",
      "iteration   3: log likelihood of observed labels = -28735.02809291\n",
      "iteration   4: log likelihood of observed labels = -28577.23326744\n",
      "iteration   5: log likelihood of observed labels = -28424.81360151\n",
      "iteration   6: log likelihood of observed labels = -28277.45822864\n",
      "iteration   7: log likelihood of observed labels = -28134.89544199\n",
      "iteration   8: log likelihood of observed labels = -27996.88176320\n",
      "iteration   9: log likelihood of observed labels = -27863.19514096\n",
      "iteration  10: log likelihood of observed labels = -27733.63061801\n",
      "iteration  11: log likelihood of observed labels = -27607.99748342\n",
      "iteration  12: log likelihood of observed labels = -27486.11732497\n",
      "iteration  13: log likelihood of observed labels = -27367.82263226\n",
      "iteration  14: log likelihood of observed labels = -27252.95574189\n",
      "iteration  15: log likelihood of observed labels = -27141.36799980\n",
      "iteration  20: log likelihood of observed labels = -26627.96398422\n",
      "iteration  30: log likelihood of observed labels = -25781.23071314\n",
      "iteration  40: log likelihood of observed labels = -25110.22403723\n",
      "iteration  50: log likelihood of observed labels = -24563.79520124\n",
      "iteration  60: log likelihood of observed labels = -24108.96761847\n",
      "iteration  70: log likelihood of observed labels = -23723.57869916\n",
      "iteration  80: log likelihood of observed labels = -23392.18892477\n",
      "iteration  90: log likelihood of observed labels = -23103.70486427\n",
      "iteration 100: log likelihood of observed labels = -22849.94105787\n",
      "iteration 200: log likelihood of observed labels = -21342.15357018\n",
      "iteration 300: log likelihood of observed labels = -20631.74142235\n",
      "iteration 400: log likelihood of observed labels = -20213.72214419\n",
      "iteration 500: log likelihood of observed labels = -19938.31784941\n"
     ]
    }
   ],
   "source": [
    "coefficients_0_penalty = logistic_regression_with_L2(feature_matrix_train, sentiment_train, initial_coefficients=np.zeros(194),\n",
    "                                   step_size=5e-6,l2_penalty=0,max_iter=501)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 345,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iteration   0: log likelihood of observed labels = -29244.55756162\n",
      "iteration   1: log likelihood of observed labels = -29067.86411732\n",
      "iteration   2: log likelihood of observed labels = -28898.01596166\n",
      "iteration   3: log likelihood of observed labels = -28734.39820110\n",
      "iteration   4: log likelihood of observed labels = -28576.54315222\n",
      "iteration   5: log likelihood of observed labels = -28424.07594854\n",
      "iteration   6: log likelihood of observed labels = -28276.68213902\n",
      "iteration   7: log likelihood of observed labels = -28134.08824493\n",
      "iteration   8: log likelihood of observed labels = -27996.04995568\n",
      "iteration   9: log likelihood of observed labels = -27862.34484727\n",
      "iteration  10: log likelihood of observed labels = -27732.76779282\n",
      "iteration  11: log likelihood of observed labels = -27607.12798351\n",
      "iteration  12: log likelihood of observed labels = -27485.24691814\n",
      "iteration  13: log likelihood of observed labels = -27366.95697994\n",
      "iteration  14: log likelihood of observed labels = -27252.10037403\n",
      "iteration  15: log likelihood of observed labels = -27140.52829086\n",
      "iteration  20: log likelihood of observed labels = -26627.27669056\n",
      "iteration  30: log likelihood of observed labels = -25781.14230326\n",
      "iteration  40: log likelihood of observed labels = -25110.99838469\n",
      "iteration  50: log likelihood of observed labels = -24565.59580548\n",
      "iteration  60: log likelihood of observed labels = -24111.89806381\n",
      "iteration  70: log likelihood of observed labels = -23727.70562579\n",
      "iteration  80: log likelihood of observed labels = -23397.55525763\n",
      "iteration  90: log likelihood of observed labels = -23110.33769822\n",
      "iteration 100: log likelihood of observed labels = -22857.85656609\n",
      "iteration 200: log likelihood of observed labels = -21362.79941952\n",
      "iteration 300: log likelihood of observed labels = -20664.13101140\n",
      "iteration 400: log likelihood of observed labels = -20256.77268191\n",
      "iteration 500: log likelihood of observed labels = -19991.06714625\n"
     ]
    }
   ],
   "source": [
    "coefficients_4_penalty = logistic_regression_with_L2(feature_matrix_train, sentiment_train, initial_coefficients=np.zeros(194),\n",
    "                                   step_size=5e-6,l2_penalty=4,max_iter=501)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 346,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iteration   0: log likelihood of observed labels = -29244.15865611\n",
      "iteration   1: log likelihood of observed labels = -29067.21939291\n",
      "iteration   2: log likelihood of observed labels = -28897.21153768\n",
      "iteration   3: log likelihood of observed labels = -28733.48298106\n",
      "iteration   4: log likelihood of observed labels = -28575.54585756\n",
      "iteration   5: log likelihood of observed labels = -28423.01468975\n",
      "iteration   6: log likelihood of observed labels = -28275.56967628\n",
      "iteration   7: log likelihood of observed labels = -28132.93479668\n",
      "iteration   8: log likelihood of observed labels = -27994.86463583\n",
      "iteration   9: log likelihood of observed labels = -27861.13635210\n",
      "iteration  10: log likelihood of observed labels = -27731.54468981\n",
      "iteration  11: log likelihood of observed labels = -27605.89879868\n",
      "iteration  12: log likelihood of observed labels = -27484.02012924\n",
      "iteration  13: log likelihood of observed labels = -27365.74097231\n",
      "iteration  14: log likelihood of observed labels = -27250.90338762\n",
      "iteration  15: log likelihood of observed labels = -27139.35837171\n",
      "iteration  20: log likelihood of observed labels = -26626.35384188\n",
      "iteration  30: log likelihood of observed labels = -25781.16001234\n",
      "iteration  40: log likelihood of observed labels = -25112.35898944\n",
      "iteration  50: log likelihood of observed labels = -24568.54914343\n",
      "iteration  60: log likelihood of observed labels = -24116.60269576\n",
      "iteration  70: log likelihood of observed labels = -23734.26382377\n",
      "iteration  80: log likelihood of observed labels = -23406.03319971\n",
      "iteration  90: log likelihood of observed labels = -23120.77749632\n",
      "iteration 100: log likelihood of observed labels = -22870.28372543\n",
      "iteration 200: log likelihood of observed labels = -21394.99282479\n",
      "iteration 300: log likelihood of observed labels = -20714.63176519\n",
      "iteration 400: log likelihood of observed labels = -20323.95779202\n",
      "iteration 500: log likelihood of observed labels = -20073.48879595\n"
     ]
    }
   ],
   "source": [
    "coefficients_10_penalty = logistic_regression_with_L2(feature_matrix_train, sentiment_train, initial_coefficients=np.zeros(194),\n",
    "                                   step_size=5e-6,l2_penalty=10,max_iter=501)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 347,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iteration   0: log likelihood of observed labels = -29238.70424674\n",
      "iteration   1: log likelihood of observed labels = -29059.21647807\n",
      "iteration   2: log likelihood of observed labels = -28888.14083697\n",
      "iteration   3: log likelihood of observed labels = -28724.06308570\n",
      "iteration   4: log likelihood of observed labels = -28566.10617287\n",
      "iteration   5: log likelihood of observed labels = -28413.69957230\n",
      "iteration   6: log likelihood of observed labels = -28266.44663700\n",
      "iteration   7: log likelihood of observed labels = -28124.04923603\n",
      "iteration   8: log likelihood of observed labels = -27986.26540336\n",
      "iteration   9: log likelihood of observed labels = -27852.88583724\n",
      "iteration  10: log likelihood of observed labels = -27723.72107335\n",
      "iteration  11: log likelihood of observed labels = -27598.59463755\n",
      "iteration  12: log likelihood of observed labels = -27477.33949677\n",
      "iteration  13: log likelihood of observed labels = -27359.79628694\n",
      "iteration  14: log likelihood of observed labels = -27245.81246459\n",
      "iteration  15: log likelihood of observed labels = -27135.24191153\n",
      "iteration  20: log likelihood of observed labels = -26628.90318964\n",
      "iteration  30: log likelihood of observed labels = -25804.70865029\n",
      "iteration  40: log likelihood of observed labels = -25164.13892722\n",
      "iteration  50: log likelihood of observed labels = -24653.19983352\n",
      "iteration  60: log likelihood of observed labels = -24237.16585091\n",
      "iteration  70: log likelihood of observed labels = -23892.78230414\n",
      "iteration  80: log likelihood of observed labels = -23603.90628670\n",
      "iteration  90: log likelihood of observed labels = -23358.97741712\n",
      "iteration 100: log likelihood of observed labels = -23149.49095074\n",
      "iteration 200: log likelihood of observed labels = -22094.58701964\n",
      "iteration 300: log likelihood of observed labels = -21825.87111894\n",
      "iteration 400: log likelihood of observed labels = -21829.38151678\n",
      "iteration 500: log likelihood of observed labels = -21955.68071958\n"
     ]
    }
   ],
   "source": [
    "coefficients_1e2_penalty = logistic_regression_with_L2(feature_matrix_train, sentiment_train, initial_coefficients=np.zeros(194),\n",
    "                                   step_size=5e-6,l2_penalty=1e2,max_iter=501)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 348,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iteration   0: log likelihood of observed labels = -29242.48043705\n",
      "iteration   1: log likelihood of observed labels = -29162.35382938\n",
      "iteration   2: log likelihood of observed labels = -29128.35003423\n",
      "iteration   3: log likelihood of observed labels = -29113.02182132\n",
      "iteration   4: log likelihood of observed labels = -29104.40037467\n",
      "iteration   5: log likelihood of observed labels = -29097.71193858\n",
      "iteration   6: log likelihood of observed labels = -29091.54245270\n",
      "iteration   7: log likelihood of observed labels = -29086.01697149\n",
      "iteration   8: log likelihood of observed labels = -29081.91400722\n",
      "iteration   9: log likelihood of observed labels = -29080.23037056\n",
      "iteration  10: log likelihood of observed labels = -29081.97024879\n",
      "iteration  11: log likelihood of observed labels = -29088.04839750\n",
      "iteration  12: log likelihood of observed labels = -29099.25192765\n",
      "iteration  13: log likelihood of observed labels = -29116.23192503\n",
      "iteration  14: log likelihood of observed labels = -29139.50972218\n",
      "iteration  15: log likelihood of observed labels = -29169.48974213\n",
      "iteration  20: log likelihood of observed labels = -29427.77232347\n",
      "iteration  30: log likelihood of observed labels = -30492.39909234\n",
      "iteration  40: log likelihood of observed labels = -32208.39895299\n",
      "iteration  50: log likelihood of observed labels = -34467.86142969\n",
      "iteration  60: log likelihood of observed labels = -37190.15395960\n",
      "iteration  70: log likelihood of observed labels = -40319.09025008\n",
      "iteration  80: log likelihood of observed labels = -43814.94703496\n",
      "iteration  90: log likelihood of observed labels = -47648.81733092\n",
      "iteration 100: log likelihood of observed labels = -51799.05308174\n",
      "iteration 200: log likelihood of observed labels = -108261.55644839\n",
      "iteration 300: log likelihood of observed labels = -188670.54001264\n",
      "iteration 400: log likelihood of observed labels = -291294.30769606\n",
      "iteration 500: log likelihood of observed labels = -415542.23427301\n"
     ]
    }
   ],
   "source": [
    "coefficients_1e3_penalty = logistic_regression_with_L2(feature_matrix_train, sentiment_train, initial_coefficients=np.zeros(194),\n",
    "                                   step_size=5e-6,l2_penalty=1e3,max_iter=501)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 349,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iteration   0: log likelihood of observed labels = -4988386.82806073\n",
      "iteration   1: log likelihood of observed labels = -19318322.41417440\n",
      "iteration   2: log likelihood of observed labels = -42994614.01387592\n",
      "iteration   3: log likelihood of observed labels = -inf\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:5: RuntimeWarning: overflow encountered in exp\n",
      "  \"\"\"\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:4: RuntimeWarning: overflow encountered in exp\n",
      "  after removing the cwd from sys.path.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iteration   4: log likelihood of observed labels = -inf\n",
      "iteration   5: log likelihood of observed labels = -inf\n",
      "iteration   6: log likelihood of observed labels = -inf\n",
      "iteration   7: log likelihood of observed labels = -inf\n",
      "iteration   8: log likelihood of observed labels = -inf\n",
      "iteration   9: log likelihood of observed labels = -inf\n",
      "iteration  10: log likelihood of observed labels = -inf\n",
      "iteration  11: log likelihood of observed labels = -inf\n",
      "iteration  12: log likelihood of observed labels = -inf\n",
      "iteration  13: log likelihood of observed labels = -inf\n",
      "iteration  14: log likelihood of observed labels = -inf\n",
      "iteration  15: log likelihood of observed labels = -inf\n",
      "iteration  20: log likelihood of observed labels = -inf\n",
      "iteration  30: log likelihood of observed labels = -inf\n",
      "iteration  40: log likelihood of observed labels = -inf\n",
      "iteration  50: log likelihood of observed labels = -inf\n",
      "iteration  60: log likelihood of observed labels = -inf\n",
      "iteration  70: log likelihood of observed labels = -inf\n",
      "iteration  80: log likelihood of observed labels = -inf\n",
      "iteration  90: log likelihood of observed labels = -inf\n",
      "iteration 100: log likelihood of observed labels = -inf\n",
      "iteration 200: log likelihood of observed labels = -inf\n",
      "iteration 300: log likelihood of observed labels = -inf\n",
      "iteration 400: log likelihood of observed labels = -inf\n",
      "iteration 500: log likelihood of observed labels = -inf\n"
     ]
    }
   ],
   "source": [
    "coefficients_1e5_penalty = logistic_regression_with_L2(feature_matrix_train, sentiment_train, initial_coefficients=np.zeros(194),\n",
    "                                   step_size=5e-6,l2_penalty=1e5,max_iter=501)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 350,
   "metadata": {},
   "outputs": [],
   "source": [
    "table = pd.DataFrame({'word': ['(intercept)'] + important_words})\n",
    "def add_coefficients_to_table(coefficients, column_name):\n",
    "    table[column_name] = coefficients\n",
    "    return table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 351,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-0.07827896,  0.08315354,  0.00478812,  0.793051  ,  1.04214059,\n",
       "        0.00659843, -0.29745287, -0.0102054 ,  0.98330568,  0.54393293,\n",
       "       -0.0955486 ,  0.19826297,  0.47400793, -0.20986097,  0.16356026,\n",
       "       -0.01742235,  0.15322576, -0.08799504, -0.12928678, -0.24907084,\n",
       "        0.15978626,  0.26936559, -0.01120742,  1.04508515, -0.04232069,\n",
       "        0.01180469, -0.06529532,  0.20368524,  0.21089238, -0.24808293,\n",
       "        0.08013072,  0.38925444, -0.06077096, -0.37184184,  0.8266464 ,\n",
       "        0.4153663 , -0.00243567, -0.13694091,  0.04428234, -0.08905391,\n",
       "       -0.13687626,  0.11245733,  0.04126887,  0.02709153, -0.16814385,\n",
       "        0.28334183,  0.08643051, -0.18594233,  0.35732899,  0.10275322,\n",
       "       -0.24712216,  0.25048661,  0.33753463, -0.11961452, -0.05378323,\n",
       "        0.16356746,  0.20600019, -0.15997569,  0.2441845 ,  0.07811893,\n",
       "        0.04100512, -0.02297006,  0.18732098,  0.15085843,  0.09344265,\n",
       "        0.07024145,  0.15743346, -0.3203447 , -0.07580772, -0.21273279,\n",
       "       -0.26376221,  0.23254957,  0.14977341,  0.00839236,  0.16480656,\n",
       "        0.08784264,  0.52346517,  0.0462256 , -0.53109812, -0.04365154,\n",
       "       -0.08574127,  0.27012075,  0.01251412,  0.55934616,  0.32761993,\n",
       "       -0.07934863,  0.17380219,  0.23774156,  0.32733686,  0.15703606,\n",
       "        0.08950266,  0.50856267, -0.04293166,  0.09743474, -0.14424322,\n",
       "        0.14469989,  0.05673235, -0.7598013 , -0.18214018, -0.33104124,\n",
       "       -0.46104378, -0.24047172, -0.34077828, -0.3424085 , -0.28432342,\n",
       "       -0.19536006, -0.92452844, -0.22246837, -0.30882214, -0.17861756,\n",
       "        0.09849733, -0.0122277 , -0.19959611, -0.61573574, -0.74023467,\n",
       "       -0.0361898 , -0.0831618 , -0.11385266, -0.05270453, -0.05796675,\n",
       "       -0.00732074, -0.06466819, -0.2085489 , -0.27813099,  0.03983556,\n",
       "       -0.14978383, -0.08424052, -0.00130848, -0.04805122, -0.00502714,\n",
       "       -0.22407007, -0.18694187, -0.20447369, -0.11051457, -0.47892175,\n",
       "       -0.20974594, -0.00352608, -0.09936188, -0.07001241, -0.09044944,\n",
       "       -0.35509663, -0.17300624,  0.06685272,  0.08326487, -0.04227274,\n",
       "        0.09851071, -0.2653335 , -0.00828057, -0.16478139, -0.02272999,\n",
       "       -0.05147927, -0.09902977, -0.06565565,  0.07392797, -0.10854751,\n",
       "        0.01927233, -0.2215467 , -0.22521257,  0.0346438 , -0.27655199,\n",
       "       -0.34780134, -0.09404694,  0.1660873 , -0.0076486 , -0.17472577,\n",
       "       -0.16040249, -0.10101037, -0.26436115, -0.0298962 , -0.55889968,\n",
       "       -0.19796717, -0.03494574, -0.55487159,  0.00687321, -0.27508639,\n",
       "       -0.15909815, -0.47789651, -0.09448226, -0.10675057, -0.12583759,\n",
       "       -0.11246908, -0.32661082, -0.00426178, -0.19997205,  0.04798296,\n",
       "       -0.20390148, -0.27228653,  0.17479999, -0.12863892,  0.06281053,\n",
       "        0.00462194, -0.20781946, -0.0440526 , -0.26028823])"
      ]
     },
     "execution_count": 351,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "coefficients_0_penalty"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 352,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>word</th>\n",
       "      <th>coefficients [L2=0]</th>\n",
       "      <th>coefficients [L2=4]</th>\n",
       "      <th>coefficients [L2=10]</th>\n",
       "      <th>coefficients [L2=1e2]</th>\n",
       "      <th>coefficients [L2=1e3]</th>\n",
       "      <th>coefficients [L2=1e5]</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>(intercept)</td>\n",
       "      <td>-0.078279</td>\n",
       "      <td>-0.067985</td>\n",
       "      <td>-0.052535</td>\n",
       "      <td>0.182813</td>\n",
       "      <td>4.191279</td>\n",
       "      <td>51.915574</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>baby</td>\n",
       "      <td>0.083154</td>\n",
       "      <td>0.085498</td>\n",
       "      <td>0.089044</td>\n",
       "      <td>0.147416</td>\n",
       "      <td>1.338858</td>\n",
       "      <td>-230.836882</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>one</td>\n",
       "      <td>0.004788</td>\n",
       "      <td>0.009123</td>\n",
       "      <td>0.015631</td>\n",
       "      <td>0.115266</td>\n",
       "      <td>1.738358</td>\n",
       "      <td>-230.845189</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>great</td>\n",
       "      <td>0.793051</td>\n",
       "      <td>0.793806</td>\n",
       "      <td>0.795017</td>\n",
       "      <td>0.823095</td>\n",
       "      <td>1.753238</td>\n",
       "      <td>-234.464324</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>love</td>\n",
       "      <td>1.042141</td>\n",
       "      <td>1.040087</td>\n",
       "      <td>1.037087</td>\n",
       "      <td>1.002775</td>\n",
       "      <td>1.244072</td>\n",
       "      <td>-238.461462</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>189</th>\n",
       "      <td>babies</td>\n",
       "      <td>0.062811</td>\n",
       "      <td>0.057863</td>\n",
       "      <td>0.050459</td>\n",
       "      <td>-0.063215</td>\n",
       "      <td>-1.508642</td>\n",
       "      <td>-248.307256</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>190</th>\n",
       "      <td>won</td>\n",
       "      <td>0.004622</td>\n",
       "      <td>-0.005318</td>\n",
       "      <td>-0.020226</td>\n",
       "      <td>-0.243615</td>\n",
       "      <td>-2.482383</td>\n",
       "      <td>-250.462480</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>191</th>\n",
       "      <td>tub</td>\n",
       "      <td>-0.207819</td>\n",
       "      <td>-0.211883</td>\n",
       "      <td>-0.218014</td>\n",
       "      <td>-0.315243</td>\n",
       "      <td>-1.863825</td>\n",
       "      <td>-249.261083</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>192</th>\n",
       "      <td>almost</td>\n",
       "      <td>-0.044053</td>\n",
       "      <td>-0.048297</td>\n",
       "      <td>-0.054668</td>\n",
       "      <td>-0.152674</td>\n",
       "      <td>-1.494411</td>\n",
       "      <td>-248.535293</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>193</th>\n",
       "      <td>either</td>\n",
       "      <td>-0.260288</td>\n",
       "      <td>-0.265595</td>\n",
       "      <td>-0.273577</td>\n",
       "      <td>-0.397371</td>\n",
       "      <td>-2.048823</td>\n",
       "      <td>-249.481089</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>194 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            word  coefficients [L2=0]  coefficients [L2=4]  \\\n",
       "0    (intercept)            -0.078279            -0.067985   \n",
       "1           baby             0.083154             0.085498   \n",
       "2            one             0.004788             0.009123   \n",
       "3          great             0.793051             0.793806   \n",
       "4           love             1.042141             1.040087   \n",
       "..           ...                  ...                  ...   \n",
       "189       babies             0.062811             0.057863   \n",
       "190          won             0.004622            -0.005318   \n",
       "191          tub            -0.207819            -0.211883   \n",
       "192       almost            -0.044053            -0.048297   \n",
       "193       either            -0.260288            -0.265595   \n",
       "\n",
       "     coefficients [L2=10]  coefficients [L2=1e2]  coefficients [L2=1e3]  \\\n",
       "0               -0.052535               0.182813               4.191279   \n",
       "1                0.089044               0.147416               1.338858   \n",
       "2                0.015631               0.115266               1.738358   \n",
       "3                0.795017               0.823095               1.753238   \n",
       "4                1.037087               1.002775               1.244072   \n",
       "..                    ...                    ...                    ...   \n",
       "189              0.050459              -0.063215              -1.508642   \n",
       "190             -0.020226              -0.243615              -2.482383   \n",
       "191             -0.218014              -0.315243              -1.863825   \n",
       "192             -0.054668              -0.152674              -1.494411   \n",
       "193             -0.273577              -0.397371              -2.048823   \n",
       "\n",
       "     coefficients [L2=1e5]  \n",
       "0                51.915574  \n",
       "1              -230.836882  \n",
       "2              -230.845189  \n",
       "3              -234.464324  \n",
       "4              -238.461462  \n",
       "..                     ...  \n",
       "189            -248.307256  \n",
       "190            -250.462480  \n",
       "191            -249.261083  \n",
       "192            -248.535293  \n",
       "193            -249.481089  \n",
       "\n",
       "[194 rows x 7 columns]"
      ]
     },
     "execution_count": 352,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "add_coefficients_to_table(coefficients_0_penalty, 'coefficients [L2=0]')\n",
    "add_coefficients_to_table(coefficients_4_penalty, 'coefficients [L2=4]')\n",
    "add_coefficients_to_table(coefficients_10_penalty, 'coefficients [L2=10]')\n",
    "add_coefficients_to_table(coefficients_1e2_penalty, 'coefficients [L2=1e2]')\n",
    "add_coefficients_to_table(coefficients_1e3_penalty, 'coefficients [L2=1e3]')\n",
    "add_coefficients_to_table(coefficients_1e5_penalty, 'coefficients [L2=1e5]')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 353,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>word</th>\n",
       "      <th>coefficients [L2=0]</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>loves</td>\n",
       "      <td>1.045085</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>love</td>\n",
       "      <td>1.042141</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>easy</td>\n",
       "      <td>0.983306</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>perfect</td>\n",
       "      <td>0.826646</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>great</td>\n",
       "      <td>0.793051</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>169</th>\n",
       "      <td>returned</td>\n",
       "      <td>-0.558900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>113</th>\n",
       "      <td>waste</td>\n",
       "      <td>-0.615736</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>114</th>\n",
       "      <td>return</td>\n",
       "      <td>-0.740235</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>money</td>\n",
       "      <td>-0.759801</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>106</th>\n",
       "      <td>disappointed</td>\n",
       "      <td>-0.924528</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>194 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             word  coefficients [L2=0]\n",
       "23          loves             1.045085\n",
       "4            love             1.042141\n",
       "8            easy             0.983306\n",
       "34        perfect             0.826646\n",
       "3           great             0.793051\n",
       "..            ...                  ...\n",
       "169      returned            -0.558900\n",
       "113         waste            -0.615736\n",
       "114        return            -0.740235\n",
       "97          money            -0.759801\n",
       "106  disappointed            -0.924528\n",
       "\n",
       "[194 rows x 2 columns]"
      ]
     },
     "execution_count": 353,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "table[['word','coefficients [L2=0]']].sort_values('coefficients [L2=0]', ascending = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 354,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "23      loves\n",
       "4        love\n",
       "8        easy\n",
       "34    perfect\n",
       "3       great\n",
       "Name: word, dtype: object"
      ]
     },
     "execution_count": 354,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "positive_words = table.sort_values('coefficients [L2=0]', ascending = False)[0:5]['word']\n",
    "positive_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 355,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "106    disappointed\n",
      "97            money\n",
      "114          return\n",
      "113           waste\n",
      "169        returned\n",
      "Name: word, dtype: object\n"
     ]
    }
   ],
   "source": [
    "negative_words = table.sort_values('coefficients [L2=0]', ascending = True)[0:5]['word']\n",
    "print(negative_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 356,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "plt.rcParams['figure.figsize'] = 10, 6\n",
    "\n",
    "def make_coefficient_plot(table, positive_words, negative_words, l2_penalty_list):\n",
    "    cmap_positive = plt.get_cmap('Reds')\n",
    "    cmap_negative = plt.get_cmap('Blues')\n",
    "    \n",
    "    xx = l2_penalty_list\n",
    "    plt.plot(xx, [0.]*len(xx), '--', lw=1, color='k')\n",
    "    \n",
    "    table_positive_words = table.loc[table['word'].isin(positive_words)]\n",
    "    table_negative_words = table.loc[table['word'].isin(negative_words)]\n",
    "    #del table_positive_words['word']\n",
    "    #del table_negative_words['word']\n",
    "    \n",
    "    for i in range(len(positive_words)):\n",
    "        color = cmap_positive(0.8*((i+1)/(len(positive_words)*1.2)+0.15))\n",
    "        plt.plot(xx, table_positive_words[i:i+1].to_numpy().flatten(),\n",
    "                 '-', label=positive_words[i], linewidth=4.0, color=color)\n",
    "        \n",
    "    for i in range(len(negative_words)):\n",
    "        color = cmap_negative(0.8*((i+1)/(len(negative_words)*1.2)+0.15))\n",
    "        plt.plot(xx, table_negative_words[i:i+1].to_numpy().flatten(),\n",
    "                 '-', label=negative_words[i], linewidth=4.0, color=color)\n",
    "        \n",
    "    plt.legend(loc='best', ncol=3, prop={'size':16}, columnspacing=0.5)\n",
    "    plt.axis([1, 1e5, -1, 2])\n",
    "    plt.title('Coefficient path')\n",
    "    plt.xlabel('L2 penalty ($\\lambda$)')\n",
    "    plt.ylabel('Coefficient value')\n",
    "    plt.xscale('log')\n",
    "    plt.rcParams.update({'font.size': 18})\n",
    "    plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 357,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "0",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-357-c52a559619f0>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mmake_coefficient_plot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtable\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpositive_words\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnegative_words\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0ml2_penalty_list\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m4\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m10\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m1e2\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m1e3\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m1e5\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-356-b3c8fd25fbe3>\u001b[0m in \u001b[0;36mmake_coefficient_plot\u001b[1;34m(table, positive_words, negative_words, l2_penalty_list)\u001b[0m\n\u001b[0;32m     18\u001b[0m         \u001b[0mcolor\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcmap_positive\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m0.8\u001b[0m\u001b[1;33m*\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m+\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m/\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpositive_words\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m*\u001b[0m\u001b[1;36m1.2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m+\u001b[0m\u001b[1;36m0.15\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     19\u001b[0m         plt.plot(xx, table_positive_words[i:i+1].to_numpy().flatten(),\n\u001b[1;32m---> 20\u001b[1;33m                  '-', label=positive_words[i], linewidth=4.0, color=color)\n\u001b[0m\u001b[0;32m     21\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     22\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnegative_words\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\pandas\\core\\series.py\u001b[0m in \u001b[0;36m__getitem__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   1069\u001b[0m         \u001b[0mkey\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcom\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mapply_if_callable\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1070\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1071\u001b[1;33m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_value\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1072\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1073\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mis_scalar\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\pandas\\core\\indexes\\base.py\u001b[0m in \u001b[0;36mget_value\u001b[1;34m(self, series, key)\u001b[0m\n\u001b[0;32m   4728\u001b[0m         \u001b[0mk\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_convert_scalar_indexer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mk\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkind\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"getitem\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   4729\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 4730\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_value\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ms\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mk\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtz\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mgetattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mseries\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"tz\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   4731\u001b[0m         \u001b[1;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   4732\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m>\u001b[0m \u001b[1;36m0\u001b[0m \u001b[1;32mand\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mholds_integer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mis_boolean\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mpandas/_libs/index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_value\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas/_libs/index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_value\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas/_libs/index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas/_libs/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.Int64HashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas/_libs/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.Int64HashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: 0"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x432 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "make_coefficient_plot(table, positive_words, negative_words, l2_penalty_list=[0, 4, 10, 1e2, 1e3, 1e5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 383,
   "metadata": {},
   "outputs": [],
   "source": [
    "def accuracy(coefficients,feature_matrix,sentiment):\n",
    "    scores = np.dot(feature_matrix, coefficients)\n",
    "    boundry = lambda x: 1 if x>0 else -1 \n",
    "    vfunc = np.vectorize(boundry)\n",
    "    predict = vfunc(scores)\n",
    "    correct_predict = (predict == sentiment).sum()\n",
    "    accuracy = correct_predict/len(feature_matrix)\n",
    "    return accuracy\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 384,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy_table = pd.DataFrame({'accuracy': ['train','test']})\n",
    "def add_accuracy_to_table(accuray, column_name):\n",
    "    print(accuray)\n",
    "    accuracy_table[column_name] = accuracy\n",
    "    return accuracy_table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 385,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy_0_train = accuracy(coefficients_0_penalty,feature_matrix_train, sentiment_train)\n",
    "accuracy_4_train = accuracy(coefficients_4_penalty, feature_matrix_train, sentiment_train)\n",
    "accuracy_10_train = accuracy(coefficients_10_penalty, feature_matrix_train, sentiment_train)\n",
    "accuracy_1e2_train = accuracy(coefficients_1e2_penalty, feature_matrix_train, sentiment_train)\n",
    "accuracy_1e3_train = accuracy(coefficients_1e3_penalty, feature_matrix_train, sentiment_train)\n",
    "accuracy_1e5_train = accuracy(coefficients_1e5_penalty, feature_matrix_train, sentiment_train)\n",
    "\n",
    "accuracy_0_valid = accuracy(coefficients_0_penalty,feature_matrix_valid, sentiment_valid)\n",
    "accuracy_4_valid = accuracy(coefficients_4_penalty, feature_matrix_valid, sentiment_valid)\n",
    "accuracy_10_valid = accuracy(coefficients_10_penalty, feature_matrix_valid, sentiment_valid)\n",
    "accuracy_1e2_valid = accuracy(coefficients_1e2_penalty, feature_matrix_valid, sentiment_valid)\n",
    "accuracy_1e3_valid = accuracy(coefficients_1e3_penalty, feature_matrix_valid, sentiment_valid)\n",
    "accuracy_1e5_valid = accuracy(coefficients_1e5_penalty, feature_matrix_valid, sentiment_valid)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 386,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy_data = pd.DataFrame(columns=['Coefficient','Train Accuracy', 'Test Accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 387,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy_data = accuracy_data.append({'Coefficient':'coefficients [L2=0]','Train Accuracy':accuracy_0_train, 'Test Accuracy': accuracy_0_valid}, ignore_index=True)\n",
    "accuracy_data = accuracy_data.append({'Coefficient':'coefficients [L2=4]','Train Accuracy':accuracy_4_train, 'Test Accuracy': accuracy_4_valid}, ignore_index=True)\n",
    "accuracy_data = accuracy_data.append({'Coefficient':'coefficients [L2=10]','Train Accuracy':accuracy_10_train, 'Test Accuracy': accuracy_10_valid}, ignore_index=True)\n",
    "accuracy_data = accuracy_data.append({'Coefficient':'coefficients [L2=1e2]','Train Accuracy':accuracy_1e2_train, 'Test Accuracy': accuracy_1e2_valid}, ignore_index=True)\n",
    "accuracy_data = accuracy_data.append({'Coefficient':'coefficients [L2=1e3]','Train Accuracy':accuracy_1e3_train, 'Test Accuracy': accuracy_1e3_valid}, ignore_index=True)\n",
    "accuracy_data = accuracy_data.append({'Coefficient':'coefficients [L2=1e5]','Train Accuracy':accuracy_1e5_train, 'Test Accuracy': accuracy_1e5_valid}, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 388,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Coefficient</th>\n",
       "      <th>Train Accuracy</th>\n",
       "      <th>Test Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>coefficients [L2=0]</td>\n",
       "      <td>0.784653</td>\n",
       "      <td>0.782289</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>coefficients [L2=4]</td>\n",
       "      <td>0.785289</td>\n",
       "      <td>0.782854</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>coefficients [L2=10]</td>\n",
       "      <td>0.785830</td>\n",
       "      <td>0.783702</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>coefficients [L2=1e2]</td>\n",
       "      <td>0.784276</td>\n",
       "      <td>0.782007</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>coefficients [L2=1e3]</td>\n",
       "      <td>0.663565</td>\n",
       "      <td>0.662647</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>coefficients [L2=1e5]</td>\n",
       "      <td>0.500813</td>\n",
       "      <td>0.499482</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             Coefficient  Train Accuracy  Test Accuracy\n",
       "0    coefficients [L2=0]        0.784653       0.782289\n",
       "1    coefficients [L2=4]        0.785289       0.782854\n",
       "2   coefficients [L2=10]        0.785830       0.783702\n",
       "3  coefficients [L2=1e2]        0.784276       0.782007\n",
       "4  coefficients [L2=1e3]        0.663565       0.662647\n",
       "5  coefficients [L2=1e5]        0.500813       0.499482"
      ]
     },
     "execution_count": 388,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 390,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "42457"
      ]
     },
     "execution_count": 390,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(feature_matrix_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
